{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-07T09:31:42.720621Z","iopub.execute_input":"2022-01-07T09:31:42.720918Z","iopub.status.idle":"2022-01-07T09:31:42.737515Z","shell.execute_reply.started":"2022-01-07T09:31:42.720865Z","shell.execute_reply":"2022-01-07T09:31:42.736826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom tqdm import tqdm\nimport transformers\n%matplotlib inline\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport nltk\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nwords = stopwords.words(\"russian\")\nlemma = nltk.stem.WordNetLemmatizer()\n\n\nimport torch\nfrom transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import BertModel\nfrom transformers import AdamW, get_linear_schedule_with_warmup\n\nimport random\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:31:42.742476Z","iopub.execute_input":"2022-01-07T09:31:42.743649Z","iopub.status.idle":"2022-01-07T09:31:45.572166Z","shell.execute_reply.started":"2022-01-07T09:31:42.743613Z","shell.execute_reply":"2022-01-07T09:31:45.571407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['salary_rating', 'team_rating', 'managment_rating', 'career_rating',\n       'workplace_rating', 'rest_recovery_rating']","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:31:45.573582Z","iopub.execute_input":"2022-01-07T09:31:45.573816Z","iopub.status.idle":"2022-01-07T09:31:45.578824Z","shell.execute_reply.started":"2022-01-07T09:31:45.573784Z","shell.execute_reply":"2022-01-07T09:31:45.578179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/headhunter-employer-review-competition/HeadHunter_train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:31:45.581339Z","iopub.execute_input":"2022-01-07T09:31:45.581771Z","iopub.status.idle":"2022-01-07T09:31:45.993876Z","shell.execute_reply.started":"2022-01-07T09:31:45.581732Z","shell.execute_reply":"2022-01-07T09:31:45.993153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:31:45.995246Z","iopub.execute_input":"2022-01-07T09:31:45.995503Z","iopub.status.idle":"2022-01-07T09:31:46.015821Z","shell.execute_reply.started":"2022-01-07T09:31:45.995467Z","shell.execute_reply":"2022-01-07T09:31:46.01506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Target_vector'] = train_df.target.apply(lambda target: [1  if number in [int(x) for x in target if x.isdigit()] else 0 for number in range(9)])","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:31:46.018151Z","iopub.execute_input":"2022-01-07T09:31:46.018941Z","iopub.status.idle":"2022-01-07T09:31:46.504927Z","shell.execute_reply.started":"2022-01-07T09:31:46.018898Z","shell.execute_reply":"2022-01-07T09:31:46.504164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df[(~train_df.positive.isna())]\ntrain_df = train_df[(~train_df.negative.isna())]","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:31:46.506053Z","iopub.execute_input":"2022-01-07T09:31:46.50634Z","iopub.status.idle":"2022-01-07T09:31:46.546669Z","shell.execute_reply.started":"2022-01-07T09:31:46.506291Z","shell.execute_reply":"2022-01-07T09:31:46.545884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.positive.apply(lambda x: len(x)).mean(), train_df.positive.apply(lambda x: len(x)).max())\nprint(train_df.negative.apply(lambda x: len(x)).mean(), train_df.negative.apply(lambda x: len(x)).max())","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:31:46.547802Z","iopub.execute_input":"2022-01-07T09:31:46.548246Z","iopub.status.idle":"2022-01-07T09:31:46.66794Z","shell.execute_reply.started":"2022-01-07T09:31:46.548206Z","shell.execute_reply":"2022-01-07T09:31:46.667085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_full = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:31:46.669472Z","iopub.execute_input":"2022-01-07T09:31:46.669733Z","iopub.status.idle":"2022-01-07T09:31:46.678387Z","shell.execute_reply.started":"2022-01-07T09:31:46.669697Z","shell.execute_reply":"2022-01-07T09:31:46.677578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val = train_test_split(train_full, test_size=0.1, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T13:21:20.957757Z","iopub.execute_input":"2022-01-07T13:21:20.958013Z","iopub.status.idle":"2022-01-07T13:21:20.976766Z","shell.execute_reply.started":"2022-01-07T13:21:20.957983Z","shell.execute_reply":"2022-01-07T13:21:20.976122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bert","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():       \n    device = torch.device(\"cuda\")\n    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n    print('Device name:', torch.cuda.get_device_name(0))\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:31:46.70042Z","iopub.execute_input":"2022-01-07T09:31:46.700683Z","iopub.status.idle":"2022-01-07T09:31:46.726901Z","shell.execute_reply.started":"2022-01-07T09:31:46.700649Z","shell.execute_reply":"2022-01-07T09:31:46.726028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased',do_lower_case=True)\n# Create a funcition to tokenize a set of text\n\ndef tokenize_text(data):\n    \"\"\"Perform required preprocessing steps for pretrained BERT.\n    @param    data (np.array): Array of texts to be processed.\n    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n                  tokens should be attended to by the model.\n    \"\"\"\n    # create empty lists to store outputs\n    input_ids = []\n    attention_masks = []\n    \n    #for every sentence...\n    \n    for sent in tqdm(data):\n        # 'encode_plus will':\n        # (1) Tokenize the sentence\n        # (2) Add the `[CLS]` and `[SEP]` token to the start and end\n        # (3) Truncate/Pad sentence to max length\n        # (4) Map tokens to their IDs\n        # (5) Create attention mask\n        # (6) Return a dictionary of outputs\n        encoded_sent = tokenizer.encode_plus(\n            sent,   #preprocess sentence\n            add_special_tokens = True,         #Add `[CLS]` and `[SEP]`\n            max_length= 512  ,             #Max length to truncate/pad\n            truncation=True,\n            pad_to_max_length = True,          #pad sentence to max length \n            return_attention_mask= True        #Return attention mask \n        )\n        # Add the outputs to the lists\n        input_ids.append(encoded_sent.get('input_ids'))\n        attention_masks.append(encoded_sent.get('attention_mask'))\n        \n    #convert lists to tensors\n    input_ids = torch.tensor(input_ids)\n    attention_masks = torch.tensor(attention_masks)\n    \n    return input_ids,attention_masks","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:31:46.728598Z","iopub.execute_input":"2022-01-07T09:31:46.728966Z","iopub.status.idle":"2022-01-07T09:31:49.26304Z","shell.execute_reply.started":"2022-01-07T09:31:46.728928Z","shell.execute_reply":"2022-01-07T09:31:49.262281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids_pos, attention_masks_pos = tokenize_text(train_df.positive.values)\ninput_ids_neg, attention_masks_neg = tokenize_text(train_df.negative.values)\ntrain_features = torch.Tensor(train_df[features].values)\ntrain_labels = train_df.Target_vector.tolist()\n\nval_input_ids_pos, val_attention_masks_pos = tokenize_text(val.positive.values)\nval_input_ids_neg, val_attention_masks_neg = tokenize_text(val.negative.values)\nval_features = torch.Tensor(val[features].values)\nval_labels = val.Target_vector.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:31:49.267833Z","iopub.execute_input":"2022-01-07T09:31:49.268039Z","iopub.status.idle":"2022-01-07T09:33:30.860529Z","shell.execute_reply.started":"2022-01-07T09:31:49.268014Z","shell.execute_reply":"2022-01-07T09:33:30.85975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = torch.Tensor(train_labels)\nval_labels = torch.Tensor(val_labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:33:30.861866Z","iopub.execute_input":"2022-01-07T09:33:30.862124Z","iopub.status.idle":"2022-01-07T09:33:30.90076Z","shell.execute_reply.started":"2022-01-07T09:33:30.862071Z","shell.execute_reply":"2022-01-07T09:33:30.900057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\n\ntrain_data = TensorDataset(input_ids_pos, attention_masks_pos, input_ids_neg, attention_masks_neg, train_features, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nval_data = TensorDataset(val_input_ids_pos, val_attention_masks_pos, val_input_ids_neg, val_attention_masks_neg, val_features, val_labels)\nval_sampler = SequentialSampler(val_data)\nval_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:33:30.902234Z","iopub.execute_input":"2022-01-07T09:33:30.902507Z","iopub.status.idle":"2022-01-07T09:33:30.910862Z","shell.execute_reply.started":"2022-01-07T09:33:30.90247Z","shell.execute_reply":"2022-01-07T09:33:30.910099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass BertClassifier(nn.Module):\n    \"\"\"\n        Bert Model for classification Tasks.\n    \"\"\"\n    def __init__(self, freeze_bert=False):\n        \"\"\"\n        @param   bert: a BertModel object\n        @param   classifier: a torch.nn.Module classifier\n        @param   freeze_bert (bool): Set `False` to fine_tune the Bert model\n        \"\"\"\n        super(BertClassifier,self).__init__()\n        # Specify hidden size of Bert, hidden size of our classifier, and number of labels\n        D_in, H,D_out = 768,30,9\n        D_in_logreg, H_logreg, D_out_logreg = 6, 30, 9\n        self.bert = BertModel.from_pretrained('DeepPavlov/rubert-base-cased')\n        \n        self.classifier = nn.Sequential(\n            nn.Dropout(0.4),\n            nn.Linear(2*D_in + 2*H_logreg, H),\n            nn.ReLU(),\n            nn.Linear(H, D_out))\n        \n        self.logreg = nn.Sequential(\n            nn.Linear(D_in_logreg, H_logreg),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(H_logreg, 2*H_logreg))\n        \n        self.sigmoid = nn.Sigmoid()\n        # Freeze the Bert Model\n        if freeze_bert:\n            for param in self.bert.parameters():\n                param.requires_grad = False\n    \n    def forward(self,input_ids_pos,attention_mask_pos, input_ids_neg,attention_mask_neg, logreg_features):\n        \"\"\"\n        Feed input to BERT and the classifier to compute logits.\n        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n                      max_length)\n        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n                      information with shape (batch_size, max_length)\n        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n                      num_labels)\n        \"\"\"\n        outputs_pos = self.bert(input_ids=input_ids_pos,\n                           attention_mask = attention_mask_pos)\n        \n        \n        outputs_neg = self.bert(input_ids=input_ids_neg,\n                           attention_mask = attention_mask_neg)\n        \n        \n        outputs_logreg = self.logreg(logreg_features)\n        \n        # Extract the last hidden state of the token `[CLS]` for classification task\n        last_hidden_state_cls_pos = outputs_pos[0][:,0,:]\n        last_hidden_state_cls_neg = outputs_neg[0][:,0,:]\n        \n        last_hidden_state_cls = torch.cat([last_hidden_state_cls_pos, last_hidden_state_cls_neg, outputs_logreg], dim=1)\n        \n        # Feed input to classifier to compute logits\n        logit = self.classifier(last_hidden_state_cls)\n        \n#         logits = self.sigmoid(logit)\n        \n        return logit","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:33:30.912502Z","iopub.execute_input":"2022-01-07T09:33:30.91303Z","iopub.status.idle":"2022-01-07T09:33:30.925583Z","shell.execute_reply.started":"2022-01-07T09:33:30.91299Z","shell.execute_reply":"2022-01-07T09:33:30.924835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_model(epochs=4):\n    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n    \"\"\"\n    \n    # Instantiate Bert Classifier\n    bert_classifier = BertClassifier(freeze_bert=False)\n    \n    bert_classifier.to(device)\n    \n    # Create the optimizer\n    optimizer = AdamW(bert_classifier.parameters(),\n                     lr=5e-5, #Default learning rate\n                     eps=1e-8 #Default epsilon value\n                     )\n    \n    # Total number of training steps\n    total_steps = len(train_dataloader) * epochs\n    \n    # Set up the learning rate scheduler\n    scheduler = get_linear_schedule_with_warmup(optimizer, \n                                              num_warmup_steps=0, # Default value\n                                              num_training_steps=total_steps)\n    return bert_classifier, optimizer, scheduler","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:33:30.926888Z","iopub.execute_input":"2022-01-07T09:33:30.927289Z","iopub.status.idle":"2022-01-07T09:33:30.938978Z","shell.execute_reply.started":"2022-01-07T09:33:30.927255Z","shell.execute_reply":"2022-01-07T09:33:30.938165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.BCEWithLogitsLoss()\n\ndef set_seed(seed_value=42):\n    \"\"\"Set seed for reproducibility.\n    \"\"\"\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    torch.cuda.manual_seed_all(seed_value)\n\ndef train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n    \"\"\"Train the BertClassifier model.\n    \"\"\"\n    print(\"Start training...\\n\")\n    for epoch_i in range(epochs):\n        # =======================================\n        #               Training\n        # =======================================\n        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n        print(\"-\"*70)\n\n        t0_epoch, t0_batch = time.time(), time.time()\n\n        total_loss, batch_loss, batch_counts = 0, 0, 0\n\n        model.train()\n\n        for step, batch in enumerate(train_dataloader):\n            batch_counts +=1\n            b_input_ids_pos, b_attn_mask_pos, b_input_ids_neg, b_attn_mask_neg, b_features, b_labels = tuple(t.to(device) for t in batch)\n\n            # Zero out any previously calculated gradients\n            model.zero_grad()\n\n            logits = model(b_input_ids_pos, b_attn_mask_pos, b_input_ids_neg, b_attn_mask_neg, b_features)\n\n            loss = loss_fn(logits, b_labels.float())\n            batch_loss += loss.item()\n            total_loss += loss.item()\n\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            optimizer.step()\n            scheduler.step()\n\n            if (step % 1000 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n                time_elapsed = time.time() - t0_batch\n\n                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n\n                batch_loss, batch_counts = 0, 0\n                t0_batch = time.time()\n\n        avg_train_loss = total_loss / len(train_dataloader)\n\n        print(\"-\"*70)\n        # =======================================\n        #               Evaluation\n        # =======================================\n        if evaluation == True:\n            val_loss, val_accuracy = evaluate(model, val_dataloader)\n\n            time_elapsed = time.time() - t0_epoch\n            \n            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n            print(\"-\"*70)\n        print(\"\\n\")\n    \n    print(\"Training complete!\")\n\n\ndef evaluate(model, val_dataloader):\n    \"\"\"After the completion of each training epoch, measure the model's performance\n    on our validation set.\n    \"\"\"\n    model.eval()\n    val_accuracy = []\n    val_loss = []\n    for batch in val_dataloader:\n        b_input_ids_pos, b_attn_mask_pos, b_input_ids_neg, b_attn_mask_neg, b_features, b_labels = tuple(t.to(device) for t in batch)\n\n        with torch.no_grad():\n            logits = model(b_input_ids_pos, b_attn_mask_pos, b_input_ids_neg, b_attn_mask_neg, b_features)\n\n        loss = loss_fn(logits, b_labels.float())\n        val_loss.append(loss.item())\n\n        accuracy = accuracy_thresh(logits.view(-1,9),b_labels.view(-1,9))\n        \n        val_accuracy.append(accuracy)\n\n    val_loss = np.mean(val_loss)\n    val_accuracy = np.mean(val_accuracy)\n\n    return val_loss, val_accuracy\n\ndef accuracy_thresh(y_pred, y_true, thresh:float=0.5, sigmoid:bool=True):\n    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n    if sigmoid: \n        y_pred = y_pred.sigmoid()\n    return ((y_pred>thresh)==y_true.byte()).float().mean().item()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T09:33:30.940335Z","iopub.execute_input":"2022-01-07T09:33:30.940618Z","iopub.status.idle":"2022-01-07T09:33:30.962217Z","shell.execute_reply.started":"2022-01-07T09:33:30.940568Z","shell.execute_reply":"2022-01-07T09:33:30.961483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\nset_seed(42)\ntrain(bert_classifier, train_dataloader, val_dataloader, epochs=1, evaluation=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T13:29:33.807483Z","iopub.execute_input":"2022-01-07T13:29:33.807754Z","iopub.status.idle":"2022-01-07T14:57:17.909222Z","shell.execute_reply.started":"2022-01-07T13:29:33.807724Z","shell.execute_reply":"2022-01-07T14:57:17.908454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/headhunter-employer-review-competition/HeadHunter_test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:59:41.202314Z","iopub.execute_input":"2022-01-07T14:59:41.20259Z","iopub.status.idle":"2022-01-07T14:59:41.579942Z","shell.execute_reply.started":"2022-01-07T14:59:41.20256Z","shell.execute_reply":"2022-01-07T14:59:41.579189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nan = test[test.positive.isna()].positive.values[0]","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:59:41.581856Z","iopub.execute_input":"2022-01-07T14:59:41.582067Z","iopub.status.idle":"2022-01-07T14:59:41.594812Z","shell.execute_reply.started":"2022-01-07T14:59:41.582041Z","shell.execute_reply":"2022-01-07T14:59:41.594019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.replace(to_replace=nan, value='')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:59:42.994779Z","iopub.execute_input":"2022-01-07T14:59:42.995198Z","iopub.status.idle":"2022-01-07T14:59:43.028021Z","shell.execute_reply.started":"2022-01-07T14:59:42.99516Z","shell.execute_reply":"2022-01-07T14:59:43.027226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids_pos_test, attention_masks_pos_test = tokenize_text(test.positive.values)\ninput_ids_neg_test, attention_masks_neg_test = tokenize_text(test.negative.values)\ntest_features = torch.Tensor(test[features].values)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T14:59:43.207441Z","iopub.execute_input":"2022-01-07T14:59:43.207695Z","iopub.status.idle":"2022-01-07T15:01:14.566342Z","shell.execute_reply.started":"2022-01-07T14:59:43.207665Z","shell.execute_reply":"2022-01-07T15:01:14.565577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = TensorDataset(input_ids_pos_test, attention_masks_pos_test, input_ids_neg_test, attention_masks_neg_test, test_features)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T15:01:14.56793Z","iopub.execute_input":"2022-01-07T15:01:14.568191Z","iopub.status.idle":"2022-01-07T15:01:14.605211Z","shell.execute_reply.started":"2022-01-07T15:01:14.568159Z","shell.execute_reply":"2022-01-07T15:01:14.602445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = {'model': bert_classifier,\n          'state_dict': bert_classifier.state_dict(),\n          'optimizer' : optimizer.state_dict()}\n\ntorch.save(checkpoint, 'checkpoint_v4_2.pth')","metadata":{"execution":{"iopub.status.busy":"2022-01-07T15:01:14.60689Z","iopub.execute_input":"2022-01-07T15:01:14.607216Z","iopub.status.idle":"2022-01-07T15:01:20.289322Z","shell.execute_reply.started":"2022-01-07T15:01:14.607171Z","shell.execute_reply":"2022-01-07T15:01:20.288335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_checkpoint(filepath):\n    checkpoint = torch.load(filepath, map_location=torch.device('cpu'))\n    model = checkpoint['model']\n    model.load_state_dict(checkpoint['state_dict'])\n    for parameter in model.parameters():\n        parameter.requires_grad = False\n\n    model.eval()\n    return model\n\n# model = load_checkpoint('/kaggle/input/bertclassifier/checkpoint.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bert_predict(model, test_dataloader):\n    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n    on the test set.\n    \"\"\"\n    model.eval()\n\n    all_logits = []\n\n    for step, batch in enumerate(test_dataloader):\n        print(step, end='\\r')\n        b_input_ids_pos, b_attn_mask_pos, b_input_ids_neg, b_attn_mask_neg, b_features = tuple(t.to(device) for t in batch)\n\n        with torch.no_grad():\n            logits = model(b_input_ids_pos, b_attn_mask_pos, b_input_ids_neg, b_attn_mask_neg, b_features)\n        all_logits.append(logits)\n    \n    all_logits = torch.cat(all_logits, dim=0)\n    probs = all_logits.sigmoid().cpu().numpy()\n    \n\n    return probs","metadata":{"execution":{"iopub.status.busy":"2022-01-07T15:39:55.800783Z","iopub.execute_input":"2022-01-07T15:39:55.801195Z","iopub.status.idle":"2022-01-07T15:39:55.808841Z","shell.execute_reply.started":"2022-01-07T15:39:55.801157Z","shell.execute_reply":"2022-01-07T15:39:55.807977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_probs = bert_predict(bert_classifier, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T15:03:56.610246Z","iopub.execute_input":"2022-01-07T15:03:56.610766Z","iopub.status.idle":"2022-01-07T15:34:59.881072Z","shell.execute_reply.started":"2022-01-07T15:03:56.610729Z","shell.execute_reply":"2022-01-07T15:34:59.880352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_probs = bert_predict(bert_classifier, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T15:36:49.140207Z","iopub.execute_input":"2022-01-07T15:36:49.140908Z","iopub.status.idle":"2022-01-07T15:39:55.799239Z","shell.execute_reply.started":"2022-01-07T15:36:49.140869Z","shell.execute_reply":"2022-01-07T15:39:55.798434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def logits_to_targets(df, probs ,thresh):\n    probs_list = [list(x) for x in probs]\n    df.Logits = probs_list\n    df['Pred_vector'] = df['Logits'].apply(lambda x: [1 if el > thresh else 0 for el in x])\n    df['Pred_vector'] = df['Pred_vector'].apply(lambda x: np.array(x))\n    df['Predict'] = df['Pred_vector'].apply(lambda x: ','.join([str(el) for el in x.nonzero()[0]]))\n    df['Predict'] = df.apply(lambda row: ','.join(str(np.argmax(row.Logits))) if row.Predict =='' else row.Predict, axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-07T15:47:53.783556Z","iopub.execute_input":"2022-01-07T15:47:53.784348Z","iopub.status.idle":"2022-01-07T15:47:53.791503Z","shell.execute_reply.started":"2022-01-07T15:47:53.784306Z","shell.execute_reply":"2022-01-07T15:47:53.79082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"binar = MultiLabelBinarizer()\nbinar = binar.fit(val.target)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T15:39:55.825688Z","iopub.execute_input":"2022-01-07T15:39:55.826761Z","iopub.status.idle":"2022-01-07T15:39:55.83447Z","shell.execute_reply.started":"2022-01-07T15:39:55.826708Z","shell.execute_reply":"2022-01-07T15:39:55.833683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = []\nfor thresh in np.linspace(start = 0, stop=1, num=51):\n    a = logits_to_targets(val, val_probs, thresh)\n    score = f1_score(binar.transform(a.target), binar.transform(a.Predict), average='samples')\n    res.append([thresh, score])","metadata":{"execution":{"iopub.status.busy":"2022-01-07T15:43:11.999494Z","iopub.execute_input":"2022-01-07T15:43:12.000082Z","iopub.status.idle":"2022-01-07T15:43:29.539417Z","shell.execute_reply.started":"2022-01-07T15:43:12.000044Z","shell.execute_reply":"2022-01-07T15:43:29.538689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(res, columns=['Threshhold','f1_score'])","metadata":{"execution":{"iopub.status.busy":"2022-01-07T15:43:30.923376Z","iopub.execute_input":"2022-01-07T15:43:30.924083Z","iopub.status.idle":"2022-01-07T15:43:30.938717Z","shell.execute_reply.started":"2022-01-07T15:43:30.924046Z","shell.execute_reply":"2022-01-07T15:43:30.937736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = logits_to_targets(test, test_probs, 0.48)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T12:31:50.210843Z","iopub.execute_input":"2022-01-07T12:31:50.211092Z","iopub.status.idle":"2022-01-07T13:02:55.812233Z","shell.execute_reply.started":"2022-01-07T12:31:50.211059Z","shell.execute_reply":"2022-01-07T13:02:55.811479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_sample = pd.read_csv('/kaggle/input/headhunter-employer-review-competition/HeadHunter_sample_submit.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.rename(columns={'Predict':'target'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T15:49:01.230906Z","iopub.execute_input":"2022-01-07T15:49:01.231184Z","iopub.status.idle":"2022-01-07T15:49:01.235962Z","shell.execute_reply.started":"2022-01-07T15:49:01.231155Z","shell.execute_reply":"2022-01-07T15:49:01.23512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[['review_id','target']].to_csv('submit.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T15:49:03.572165Z","iopub.execute_input":"2022-01-07T15:49:03.572613Z","iopub.status.idle":"2022-01-07T15:49:03.661129Z","shell.execute_reply.started":"2022-01-07T15:49:03.572577Z","shell.execute_reply":"2022-01-07T15:49:03.66039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_sample.to_csv('sub.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}